using System.Net;
using System.Net.Http.Json;
using System.Text.Json;
using FreelanceAI.Core.Constants;
using FreelanceAI.Core.Interfaces;
using FreelanceAI.Core.Models;
using Microsoft.Extensions.Configuration;
using Microsoft.Extensions.Logging;

namespace FreelanceAI.ApiRouter.Providers;

public class OllamaProvider : IAIProvider
{
    private readonly string _baseUrl;
    private readonly string _defaultModel;
    private readonly HttpClient _httpClient;
    private readonly ILogger<OllamaProvider> _logger;

    public OllamaProvider(HttpClient httpClient, IConfiguration config, ILogger<OllamaProvider> logger)
    {
        _httpClient = httpClient;
        _logger = logger;
        _baseUrl = config["Ollama:BaseUrl"] ?? OllamaConstants.BaseUrl;
        _defaultModel = config["Ollama:DefaultModel"] ?? OllamaConstants.Model;

        _httpClient.BaseAddress = new Uri(_baseUrl);
        _httpClient.Timeout = TimeSpan.FromMinutes(5); // Ollama can be slow for large models
    }

    public string Name => "Ollama";
    public int Priority => 99; // Last resort (local fallback)
    public decimal CostPerToken => 0.0m; // Completely free
    public bool IsAvailable { get; private set; } = true;

    public async Task<string> GenerateAsync(string prompt, AIRequestOptions options)
    {
        try
        {
            var request = new
            {
                model = _defaultModel,
                prompt = $"System: You are an expert developer assistant.\n\nUser: {prompt}",
                stream = false,
                options = new
                {
                    temperature = options.Temperature,
                    num_predict = options.MaxTokens
                }
            };

            _logger.LogDebug("Sending request to Ollama: {Model} at {BaseUrl}", request.model, _baseUrl);

            var response = await _httpClient.PostAsJsonAsync("api/generate", request);

            if (!response.IsSuccessStatusCode)
            {
                var errorContent = await response.Content.ReadAsStringAsync();
                _logger.LogError("Ollama API returned error {StatusCode}: {Error}",
                    response.StatusCode, errorContent);

                // Mark as unavailable for service-level errors
                if (response.StatusCode == HttpStatusCode.ServiceUnavailable ||
                    response.StatusCode == HttpStatusCode.InternalServerError)
                    IsAvailable = false;

                throw new HttpRequestException($"Ollama API error: {response.StatusCode} - {errorContent}");
            }

            var content = await response.Content.ReadAsStringAsync();

            if (string.IsNullOrEmpty(content))
            {
                _logger.LogError("Ollama API returned empty response");
                throw new InvalidOperationException("Empty response from Ollama API");
            }

            var result = JsonSerializer.Deserialize<OllamaResponse>(content, new JsonSerializerOptions
            {
                PropertyNameCaseInsensitive = true
            });

            if (result?.Response == null)
            {
                _logger.LogError("Ollama API response missing 'response' field: {Content}", content);
                throw new InvalidOperationException("Invalid response structure from Ollama API");
            }

            if (string.IsNullOrEmpty(result.Response))
            {
                _logger.LogError("Ollama API returned empty generated text");
                throw new InvalidOperationException("No content generated by Ollama API");
            }

            _logger.LogDebug("Received response from Ollama: {Length} characters", result.Response.Length);

            return result.Response;
        }
        catch (HttpRequestException ex)
        {
            _logger.LogError(ex, "HTTP error calling Ollama at {BaseUrl}", _baseUrl);
            IsAvailable = false;
            throw new InvalidOperationException($"Ollama service unavailable at {_baseUrl}: {ex.Message}", ex);
        }
        catch (TaskCanceledException ex) when (ex.InnerException is TimeoutException)
        {
            _logger.LogError(ex, "Timeout calling Ollama at {BaseUrl}", _baseUrl);
            throw new InvalidOperationException($"Ollama request timed out at {_baseUrl}", ex);
        }
        catch (TaskCanceledException ex)
        {
            _logger.LogError(ex, "Request was cancelled calling Ollama at {BaseUrl}", _baseUrl);
            throw new InvalidOperationException($"Ollama request was cancelled at {_baseUrl}", ex);
        }
        catch (JsonException ex)
        {
            _logger.LogError(ex, "Failed to parse Ollama API response");
            throw new InvalidOperationException($"Invalid JSON response from Ollama API: {ex.Message}", ex);
        }
        catch (InvalidOperationException)
        {
            // Re-throw our own exceptions as-is
            throw;
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Unexpected error calling Ollama at {BaseUrl}", _baseUrl);
            throw new InvalidOperationException($"Unexpected error from Ollama API: {ex.Message}", ex);
        }
    }

    public async Task<bool> CheckHealthAsync()
    {
        try
        {
            _logger.LogDebug("Checking Ollama health at {BaseUrl}", _baseUrl);

            var response = await _httpClient.GetAsync("api/tags");

            if (!response.IsSuccessStatusCode)
            {
                var errorContent = await response.Content.ReadAsStringAsync();
                _logger.LogWarning("Ollama health check failed with status: {StatusCode}, Error: {Error}",
                    response.StatusCode, errorContent);
                IsAvailable = false;
                return false;
            }

            var content = await response.Content.ReadAsStringAsync();

            if (string.IsNullOrEmpty(content))
            {
                _logger.LogWarning("Ollama health check returned empty response");
                IsAvailable = false;
                return false;
            }

            var result = JsonSerializer.Deserialize<OllamaTagsResponse>(content, new JsonSerializerOptions
            {
                PropertyNameCaseInsensitive = true
            });

            var modelCount = result?.Models?.Length ?? 0;
            IsAvailable = true;

            _logger.LogDebug("Ollama health check passed. {ModelCount} models available", modelCount);

            // Log available models for debugging
            if (result?.Models != null && result.Models.Length > 0)
            {
                _logger.LogDebug("Available Ollama models:");
                foreach (var model in result.Models)
                    _logger.LogDebug("  - {ModelName} ({ModelSize})", model.Name ?? "Unknown",
                        model.Size ?? "Unknown size");

                // Check if our preferred model is available
                var hasPreferredModel = result.Models.Any(m =>
                    m.Name != null && (m.Name.Contains("deepseek-coder") || m.Name.Contains("codellama")));

                if (!hasPreferredModel)
                    _logger.LogWarning("Preferred coding models (deepseek-coder, codellama) not found. " +
                                       "Consider running: ollama pull {DefaultModel}", _defaultModel);

                // Check if the configured default model is available
                var hasDefaultModel = result.Models.Any(m =>
                    m.Name != null && m.Name.Equals(_defaultModel, StringComparison.OrdinalIgnoreCase));

                if (!hasDefaultModel)
                    _logger.LogWarning("Configured default model '{DefaultModel}' not found. " +
                                       "Run 'ollama pull {DefaultModel}' to install it.", _defaultModel, _defaultModel);
            }
            else
            {
                _logger.LogWarning(
                    "No models found in Ollama. Run 'ollama pull {DefaultModel}' to install a coding model.",
                    _defaultModel);
            }

            return IsAvailable;
        }
        catch (TaskCanceledException ex)
        {
            _logger.LogWarning(ex, "Ollama health check timed out at {BaseUrl}", _baseUrl);
            IsAvailable = false;
            return false;
        }
        catch (JsonException ex)
        {
            _logger.LogError(ex, "Failed to parse Ollama health check response");
            IsAvailable = false;
            return false;
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Ollama health check failed at {BaseUrl}", _baseUrl);
            IsAvailable = false;
            return false;
        }
    }

    private record OllamaResponse(string? Response);

    private record OllamaTagsResponse(OllamaModel[]? Models);

    // ReSharper disable once ClassNeverInstantiated.Local
    // gets mapped by JsonSerializer.Deserialize method no need for init here
    private record OllamaModel(string? Name, string? Size, string? Digest);
}